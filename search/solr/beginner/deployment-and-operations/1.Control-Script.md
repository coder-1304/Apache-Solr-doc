Solr includes a script called `bin/solr` that facilitates common operations on your Solr installation or cluster. This script allows you to start and stop Solr, manage collections or cores, interact with ZooKeeper, and check the status of Solr and configured shards.

You can locate the `bin/solr` script in the `bin/` directory of your Solr installation. It simplifies Solr management by offering straightforward commands and options to efficiently achieve various tasks.

# Starting and Stopping
## Start and Restart
The `start` command initiates Solr, while the `restart` command restarts Solr if it's already running or has been stopped.

Both commands offer options to run in SolrCloud mode, utilize an example configuration set, specify a non-default hostname or port, and connect to a local ZooKeeper ensemble.

- Start Solr: `bin/solr start [options]`
- Start command help: `bin/solr start -help`
- Restart Solr: `bin/solr restart [options]`
- Restart command help: `bin/solr restart -help`

When using the `restart` command, ensure to include all parameters initially used to start Solr. Internally, a stop request is triggered to stop Solr before restarting. If no nodes are running, the restart command skips the stop step and proceeds directly to starting Solr.

## Solr Command Line Options

### -a "options"

Start Solr with additional JVM parameters. These parameters can include options that start with `-X`, which are typically used to configure the Java Virtual Machine (JVM). 

If you need to pass JVM parameters that begin with "-D" (for example, `-Dsolr.port=8983`), you can omit the `-a` option.

Example:
```bash
bin/solr start -a "-Xdebug -Xrunjdwp:transport=dt_socket, server=y,suspend=n,address=1044"
```
In this example, Solr is started with additional JVM parameters `-Xdebug -Xrunjdwp:transport=dt_socket, server=y,suspend=n,address=1044`, which are used for remote debugging. This allows you to connect a debugger to Solr to diagnose issues or inspect the runtime behavior.

### -cloud

- Start Solr in SolrCloud mode, which will also launch the embedded ZooKeeper instance included with Solr.

- This option can be shortened to simply -c.

- If you are already running a ZooKeeper ensemble that you want to use instead of the embedded (single-node) ZooKeeper, you should also either specify ZK_HOST in solr.in.sh/solr.in.cmd or pass the -z parameter.

- Example: `bin/solr start -c`

### -d <dir>

- Define a server directory, defaults to server (as in, $SOLR_HOME/server). It is uncommon to override this option. When running multiple instances of Solr on the same host, it is more common to use the same server directory for each instance and use a unique Solr home directory using the -s option.

- Example: `bin/solr start -d newServerDir`

### -e <name>

Start Solr with an example configuration. These examples are provided to help you get started faster with Solr generally, or just try a specific feature.

The available options are:

- `cloud`: Start Solr in SolrCloud mode with an example configuration.
- `techproducts`: Start Solr with an example configuration for the TechProducts demo.
- `dih`: Start Solr with an example configuration for the DataImportHandler (DIH).
- `schemaless`: Start Solr with an example configuration for Schemaless mode.

Example: `bin/solr start -e schemaless`

### -f

Start Solr in the foreground. This means that Solr will run in the current terminal session, and you will see its output directly. Note that you cannot use this option when running examples with the `-e` option.

Example: `bin/solr start -f`

### -h <hostname>

Specify the hostname on which Solr should listen. If you don't specify a hostname, Solr will default to 'localhost', meaning it will only be accessible from the local machine.

Example: `bin/solr start -h search.mysolr.com`

In this command, Solr will start with the hostname search.mysolr.com. This means Solr will bind to the network interface associated with that hostname, allowing it to be accessed using that hostname from other machines on the network.

### -m <memory>

Set the minimum and maximum heap size for the Java Virtual Machine (JVM) that runs Solr. This option allows you to allocate a specific amount of memory to Solr, which can be useful for optimizing performance.

Example: `bin/solr start -m 1g`

### -noprompt

Start Solr without prompting for any additional configuration. This option is useful if you want to start Solr with all default settings.

Example: `bin/solr start -e cloud -noprompt`

### -p <port>

Specify the port on which Solr should listen for incoming connections. If you don't specify a port, Solr will default to port '8983'.

Example: `bin/solr start -p 8655`

### -s <dir>

Set the directory where Solr will create core directories. This option allows you to run multiple Solr instances on the same host while reusing the same server directory.

Example: `bin/solr start -s newHome`

### -v

Enable verbose mode, which increases the logging level of Solr. This changes the logging level of log4j from INFO to DEBUG. It can be useful for debugging purposes.

Example: `bin/solr start -f -v`

### -q

Enable quiet mode, which reduces the logging level of Solr. This can be useful in production settings where you want to limit logging to warnings and errors.

Example: `bin/solr start -f -q`

### -V

Start Solr with verbose messages from the start script. This can provide additional information about the startup process.

Example: `bin/solr start -V`

### -z <zkHost>

Specify the ZooKeeper connection string for SolrCloud mode. This option is used to connect Solr to an external ZooKeeper ensemble.

Example: `bin/solr start -c -z server1:2181,server2:2181`

### -force

Forcefully start Solr even if running as the root user. Normally, starting Solr as root is not recommended due to potential security risks.

Example: `sudo bin/solr start -force`

> It is not necessary to define all of the options when starting if the defaults are fine for your needs.


## Running with Example Configurations

The `bin/solr start -e <name>` command allows you to quickly get started with Solr using example configurations tailored to different use cases. These examples help you set up Solr for your specific needs without needing to manually configure everything from scratch.

### Example Configurations

- **cloud:** Starts a 1-4 node SolrCloud cluster on a single machine. An interactive session guides you through selecting the initial configset, number of nodes, ports, and collection name. Configsets can be chosen from `$SOLR_HOME/server/solr/configsets`.

- **techproducts:** Starts Solr in standalone mode with a schema designed for the sample documents in `$SOLR_HOME/example/exampledocs`.

- **dih:** Starts Solr in standalone mode with the DataImportHandler (DIH) enabled. Includes pre-configured `dataconfig.xml` files for different types of data sources supported by DIH. Configurations can be found in `$SOLR_HOME/example/example-DIH/solr/conf`.

- **schemaless:** Starts Solr in standalone mode with a managed schema, allowing dynamic field creation based on incoming documents. Configuration can be found in `$SOLR_HOME/server/solr/configsets/_default`.

Unless specified, these examples do not enable SolrCloud or schemaless mode. If you prefer manual editing of the `schema.xml` file, you can change this default setting as described in the "Schema Factory Definition in SolrConfig" section.


## Stop Command

The `stop` command is used to gracefully shut down a running Solr node. It sends a STOP request to the Solr node, allowing it to shut down properly. If the node does not shut down within 180 seconds, the command will forcefully kill the process. Here are the key options for the `stop` command:

- `-p <port>`: Stops the Solr instance running on the specified port.
  Example: `bin/solr stop -p 8983`

- `-all`: Stops all running Solr instances with a valid PID.
  Example: `bin/solr stop -all`

- `-k <key>`: Specifies a stop key to protect against inadvertently stopping Solr. The default key is "solrrocks".
  Example: `bin/solr stop -k solrrocks`

# System Information

## Version Command

The `version` command simply returns the version of Solr currently installed.
Example: `$ bin/solr version` - This will output the version number, such as "X.Y.0".

## Status Command

The `status` command displays basic information about any Solr nodes found running on the local system in JSON format. It uses the `SOLR_PID_DIR` environment variable to locate Solr process ID files, which defaults to the bin directory.
Example: `bin/solr status` - This will display the status of the running Solr nodes.

The output will include a status of each node of the cluster, for example:
```json
Found 2 Solr nodes:

Solr process 39920 running on port 7574
{
  "solr_home":"/Applications/Solr/example/cloud/node2/solr/",
  "version":"X.Y.0",
  "startTime":"2015-02-10T17:19:54.739Z",
  "uptime":"1 days, 23 hours, 55 minutes, 48 seconds",
  "memory":"77.2 MB (%15.7) of 490.7 MB",
  "cloud":{
    "ZooKeeper":"localhost:9865",
    "liveNodes":"2",
    "collections":"2"}}

Solr process 39827 running on port 8865
{
  "solr_home":"/Applications/Solr/example/cloud/node1/solr/",
  "version":"X.Y.0",
  "startTime":"2015-02-10T17:19:49.057Z",
  "uptime":"1 days, 23 hours, 55 minutes, 54 seconds",
  "memory":"94.2 MB (%19.2) of 490.7 MB",
  "cloud":{
    "ZooKeeper":"localhost:9865",
    "liveNodes":"2",
    "collections":"2"}}
```

## Healthcheck Command

The `healthcheck` command in SolrCloud mode generates a health report for a collection in JSON format. This report contains information about each replica's state for all shards in the collection, including the number of committed documents and its current status.

```bash
bin/solr healthcheck [options]
```

- `-c <collection>`: Specifies the name of the collection to run the health check against. This parameter is required.
Example:
```bash
bin/solr healthcheck -c gettingstarted
```

- `-z <zkhost>`: Specifies the ZooKeeper connection string. It defaults to localhost:9983 but should be specified if Solr is running on a port other than 8983. If ZK_HOST is defined in solr.in.sh or solr.in.cmd, this option is unnecessary.
Example:
```bash
bin/solr healthcheck -z localhost:2181
```

```json
{
  "collection":"gettingstarted",
  "status":"healthy",
  "numDocs":0,
  "numShards":2,
  "shards":[
    {
      "shard":"shard1",
      "status":"healthy",
      "replicas":[
        {
          "name":"core_node1",
          "url":"http://10.0.1.10:8865/solr/gettingstarted_shard1_replica2/",
          "numDocs":0,
          "status":"active",
          "uptime":"2 days, 1 hours, 18 minutes, 48 seconds",
          "memory":"25.6 MB (%5.2) of 490.7 MB",
          "leader":true},
        {
          "name":"core_node4",
          "url":"http://10.0.1.10:7574/solr/gettingstarted_shard1_replica1/",
          "numDocs":0,
          "status":"active",
          "uptime":"2 days, 1 hours, 18 minutes, 42 seconds",
          "memory":"95.3 MB (%19.4) of 490.7 MB"}]},
    {
      "shard":"shard2",
      "status":"healthy",
      "replicas":[
        {
          "name":"core_node2",
          "url":"http://10.0.1.10:8865/solr/gettingstarted_shard2_replica2/",
          "numDocs":0,
          "status":"active",
          "uptime":"2 days, 1 hours, 18 minutes, 48 seconds",
          "memory":"25.8 MB (%5.3) of 490.7 MB"},
        {
          "name":"core_node3",
          "url":"http://10.0.1.10:7574/solr/gettingstarted_shard2_replica1/",
          "numDocs":0,
          "status":"active",
          "uptime":"2 days, 1 hours, 18 minutes, 42 seconds",
          "memory":"95.4 MB (%19.4) of 490.7 MB",
          "leader":true}]}]}
```


# Collections and Cores

Collections and Cores in Solr represent units of data storage and retrieval. They can be created using the `bin/solr` script, which is capable of creating new collections in SolrCloud mode or cores in standalone mode, as well as deleting existing collections.

## Creating a Core and Collection

To create a Core or Collection using the `bin/solr` script, you need to use the `create` command followed by specific options:

```bash
bin/solr create [options]
```

For help with available options, you can use:

```bash
bin/solr create -help
```
### Create Core or Collection Parameters
Here are some key parameters for creating Cores or Collections:

- `-c <name>`: Specifies the name of the core or collection you want to create. This parameter is required.

Example:
```bash
bin/solr create -c mycollection
```

- `-d <confdir>`: Specifies the configuration directory. If not specified, it defaults to _default.

Example:
```bash
bin/solr create -d _default
```

- `-n <configName>`: Specifies the configuration name. By default, it's the same as the core or collection name. </br>

Example:
```bash
bin/solr create -n basic
```

- `-p <port>`: Specifies the port of the local Solr instance to send the create command to. By default, the script tries to detect the port by searching for running Solr instances. Useful for specifying the instance if multiple standalone Solr instances are running on the same host.

Example:
```bash
bin/solr create -p 8983
```

- `-s <shards>` or `-shards`: Specifies the number of shards to split a collection into. Default is 1 and only applies when Solr is running in SolrCloud mode.

Example:
```bash
bin/solr create -s 2
```
- `-rf <replicas>` or `-replicationFactor`: Specifies the number of copies of each document in the collection. Default is 1 (no replication).

Example:
```bash
bin/solr create -rf 2
```

- `-force`: Overrides warnings when attempting to run create as the "root" user. Running Solr or actions against Solr as "root" can cause problems, so this option should be used with caution.

Example:
```bash
bin/solr create -c foo -force
```

</br>

### SolrCloud Configuration Directories

In SolrCloud, before creating a collection, you must upload the configuration directory for that collection to ZooKeeper. The `create` command in Solr supports various scenarios for how collections and configuration directories interact. The primary decision revolves around whether a configuration directory in ZooKeeper should be shared across multiple collections.

Let's break it down with some examples to better understand how configuration directories function in SolrCloud.

#### Default Configuration Directory

If you don't specify the `-d` or `-n` options, the default configuration (located at `$SOLR_HOME/server/solr/configsets/_default/conf`) is uploaded to ZooKeeper with the same name as the collection being created.

For instance, running `bin/solr create -c contacts` will upload the `_default` configuration to `/configs/contacts` in ZooKeeper.

#### Unique Configuration Directory for Each Collection

By default, each collection gets its own unique copy of the configuration directory. So, creating another collection like `contacts2` with `bin/solr create -c contacts2` will upload another copy of the `_default` directory to `/configs/contacts2` in ZooKeeper.

Changes made to the configuration of one collection won't affect others. Each collection has its own isolated configuration.

#### Override Configuration Directory Name

You can override the name given to the configuration directory in ZooKeeper using the `-n` option. For example, running `bin/solr create -c logs -d _default -n basic` will upload the `_default` directory to ZooKeeper as `/configs/basic`.

Here, we used the `-d` option to specify a different configuration than the default. Solr provides built-in configurations under `server/solr/configsets`, but you can also provide the path to your own configuration directory using the `-d` option.

#### Sharing Configuration Across Collections

Collections can share the same configuration by specifying the name of the shared configuration using the `-n` option. For example, `bin/solr create -c logs2 -n basic` will create a new collection that shares the `basic` configuration created previously.

</br>

### Data-driven Schema and Shared Configurations

In Solr, the _default schema has a unique feature called schemaless functionality. This means that the schema can dynamically evolve as data is indexed. In simpler terms, the schema adapts and changes based on the type of data being indexed.

Now, because of this dynamic nature, it's important to understand that sharing this kind of data-driven schema between collections can have consequences. If you share a schema between collections, any changes made to the schema due to indexing data into one collection will affect all other collections sharing the same schema.

To clarify, if you're certain that all collections should inherit the changes made when indexing data into one collection, then sharing the data-driven configuration might be appropriate. However, if you want to prevent this automatic schema evolution for a specific collection, you can turn off the schemaless functionality.

Here's how you can turn off schemaless functionality for a collection named mycollection:

```bash
bin/solr config -c mycollection -p 8983 -action set-user-property -property update.autoCreateFields -value false
```

This command effectively disables the automatic creation of fields based on incoming data for the specified collection.

## Delete Core or Collection


To delete a core or collection in Solr, you can use the delete command provided by the bin/solr script. This command detects whether Solr is running in standalone mode or SolrCloud mode and then proceeds to delete the specified core or collection accordingly.

Here's how you can use the delete command:

```bash
bin/solr delete [options]
```
To get help with available options, you can use:

```bash
bin/solr delete -help
```

When running in SolrCloud mode, the delete command not only removes the specified core or collection but also checks if the configuration directory used by the collection being deleted is shared by other collections. If the configuration directory is not shared, it will also be deleted from ZooKeeper.

For example, if you created a collection named contacts using `bin/solr create -c contacts`, running the delete command `bin/solr delete -c contacts` will first check if the /configs/contacts configuration directory is used by any other collections. If not, it will delete the contacts collection and remove the configs/contacts directory from ZooKeeper.

Here are some parameters you can use with the delete command:

- `-c <name>`: Specifies the name of the core or collection to delete. This parameter is required.
Example:
```bash
bin/solr delete -c mycollection
```

- `-deleteConfig`: Specifies whether the configuration directory should also be deleted from ZooKeeper. By default, this is set to true. If the configuration directory is being used by another collection, it won't be deleted even if you set -deleteConfig to true.
Example:
```bash
bin/solr delete -deleteConfig false
```

- `-p <port>`: Specifies the port of the local Solr instance to send the delete command to. By default, the script tries to detect the port by searching for running Solr instances. This option is useful if you're running multiple standalone Solr instances on the same host and need to specify which instance to delete the core from.
Example:
```bash
bin/solr delete -p 8983
```

# Authentication in Solr

Authentication in Solr allows you to control access to Solr resources by enabling or disabling Basic Authentication. This can be done using the `bin/solr` script from the command line. Currently, Basic Authentication is the only authentication method supported by this script, and it is applicable only when using SolrCloud mode.

## Enabling Basic Authentication

Enabling Basic Authentication with the `bin/solr auth enable` command configures Solr to require users to authenticate themselves when accessing the Solr User Interface or making API requests through `bin/solr`.

This command makes several changes to enable Basic Authentication:

1. It creates a `security.json` file with authentication and authorization configurations and uploads it to ZooKeeper. This file defines settings such as whether to block unknown users from accessing Solr and specifies the initial user credentials.

2. It adds two lines to the `bin/solr.in.sh` or `bin\solr.in.cmd` file to set the authentication type and the path to the `basicAuth.conf` file.

3. It creates the `basicAuth.conf` file in the `server/solr` directory to store credential information used by `bin/solr` commands.

The `bin/solr auth enable` command accepts several parameters:

- `-credentials`: Specifies the username and password of the initial user in the format `username:password`.
- `-prompt`: If preferred, prompts the user to enter a username and password interactively.
- `-blockUnknown`: When set to true, blocks all unauthenticated users from accessing Solr.
- `-updateIncludeFileOnly`: When set to true, only updates the configuration files without creating a new `security.json`.
- `-z`, `-d`, `-s`: Additional parameters to define ZooKeeper connect string, Solr server directory, and Solr home directory path, respectively.

### Example to enable authentication:

Run this command to enable authentication with credentials (username=admin, password=solrpass):
```bash
bin/solr auth enable -credentials admin:solrpass -blockUnknown true
```
After running this, you will see something like:
```json
{
  "authentication":{
   "blockUnknown": false,
   "class":"solr.BasicAuthPlugin",
   "credentials":{"admin":"pEdfQz5CIyp/fD9aRgX0bjMD8e374uFlcdD/XY6dfhE8= 4CiBFjr91xYNaVabXVIYNyJ+ZeKMYUUu3StyDVssItI="}
  },
  "authorization":{
   "class":"solr.RuleBasedAuthorizationPlugin",
   "permissions":[
 {"name":"security-edit", "role":"admin"},
 {"name":"security-read", "role":"admin"},
 {"name":"config-edit", "role":"admin"},
 {"name":"config-read", "role":"admin"},
 {"name":"collection-admin-edit", "role":"admin"},
 {"name":"collection-admin-read", "role":"admin"},
 {"name":"core-admin-edit", "role":"admin"},
 {"name":"core-admin-read", "role":"admin"},
 {"name":"all", "role":"admin"}
   ],
   "user-role":{"admin":"admin"}
  }
}
```
Notice that blockUnknown is set to true. This mean you have to enter credentials while accessing Solr.

For example if you perform a search operation using url, you have to add basic auth with username and password that you have set.

## Disabling Basic Authentication in Solr

To disable Basic Authentication in Solr, you can use the command `bin/solr auth disable`.

When running this command:

- If you set the `-updateIncludeFileOnly` option to true, only the settings in `bin/solr.in.sh` or `bin\solr.in.cmd` will be updated, and the `security.json` file will not be removed.

- If you set the `-updateIncludeFileOnly` option to false, the settings in `bin/solr.in.sh` or `bin\solr.in.cmd` will be updated, and the `security.json` file will be removed. However, the `basicAuth.conf` file will not be removed with either option.

In essence, using `bin/solr auth disable` allows you to easily turn off Basic Authentication in Solr, and you can choose whether to remove the security configuration entirely or just update the configuration files.



# Setting or Unsetting Configuration Properties

The `bin/solr` script helps you manage settings in Apache Solr through a simplified Config API. This means you can easily adjust common and user-defined properties.

## Setting or Unsetting Common Properties

Let's say you want to adjust a common property, like how often documents are automatically committed. Here's how you can do it:

```bash
bin/solr config -c mycollection -p 8983 -action set-property -property updateHandler.autoCommit.maxDocs -value 100
```

The default -action is set-property, so the above can be shortened by not mentioning it

```bash
bin/solr config -c mycollection -p 8983 -property updateHandler.autoCommit.maxDocs -value 100
```

If you want to undo a change you've made previously, simply use:
```bash
bin/solr config -c mycollection -p 8983 -action unset-property -property updateHandler.autoCommit.maxDocs -value 100
```
> We don't directly make indexed documents available for searching because using an indexing buffer offers several advantages. The buffering mechanism optimizes performance by batching changes, resulting in fewer, larger disk writes, which are less resource-intensive and faster than frequent small writes. Additionally, buffering ensures data consistency by first writing changes to a temporary buffer before committing them to the main index. This helps prevent inconsistencies in the index, especially in the event of errors during the indexing process. Furthermore, buffering facilitates atomic updates, where multiple changes are applied as a single operation, ensuring either all changes are successfully applied or none at all. Overall, the indexing buffer enhances performance, maintains data integrity, and supports efficient indexing processes in systems like Apache Solr.
 

## Setting or Unsetting User-defined Properties
Now, if you're working with user-defined properties, like turning off Schemaless Mode, you can do it like this:

```bash
bin/solr config -c mycollection -p 8983 -action set-user-property -property update.autoCreateFields -value false
```
To undo this change later on, specify `-action unset-user-property` with no `-value`:

```bash
bin/solr config -c mycollection -p 8983 -action unset-user-property -property update.autoCreateFields
```

## Config Parameters
Here are some key parameters you need to know:

- `-c <name>`: Specify the name of the core or collection you're configuring.
- `-action <name>`: Choose an action like setting or unsetting properties. Defaults to setting.
- `-property <name>`: Name the property you want to adjust.
- `-value <new-value>`: Set the property to a new value.
- `-z <zkHost>`: If you're using SolrCloud, provide the ZooKeeper connection string.
- `-p <port>`: Specify the port of the Solr node you're working with.
- `-solrUrl <url>`: Base Solr URL, helpful for SolrCloud setups.


# ZooKeeper Operations in Apache Solr

In Apache Solr, the `bin/solr` script offers functionalities for managing ZooKeeper, a key component in SolrCloud mode. These operations are crucial for distributed setups where Solr runs across multiple nodes for scalability and fault tolerance. The script provides various sub-commands, each with its own options, to interact with ZooKeeper.

## Usage Overview

You can access ZooKeeper operations using the following syntax:

```bash
bin/solr zk [sub-command] [options]
```
For help and available commands, you can use:
```bash
bin/solr zk -help
```

**Prerequisite**:
Before executing ZooKeeper operations, Solr should have been started at least once. This ensures that ZooKeeper is properly initialized with the necessary configuration data. Once initialized, Solr doesn't need to be actively running to execute ZooKeeper commands.
> When starting Solr in SolrCloud mode, ZooKeeper is automatically initialized as a part of the setup process. You do not need to explicitly initialize ZooKeeper themselves. To determine which port ZooKeeper is initialized on, users can check the command used to start Solr in SolrCloud mode. By inspecting this command, you can easily identify the port on which ZooKeeper is initialized and interact with it accordingly.

## Upload a Configuration Set
To upload a configuration set to ZooKeeper, you use the `zk upconfig` command. This allows you to upload either a pre-configured set or a customized set.

**Parameters**
- `-n <name>`: Specifies the name of the configuration set in ZooKeeper. This name is used to identify the configuration set and will be associated with the "configs" ZooKeeper node.
- `-d <configset dir>`: Indicates the path to the configuration set to be uploaded. This directory should contain a conf subdirectory with essential configuration files like solrconfig.xml.
- `-z <zkHost>`: Specifies the ZooKeeper connection string. If not defined in Solr's configuration files, you must provide it explicitly.

**Example Command**
```bash
bin/solr zk upconfig -z 111.222.333.444:2181 -n mynewconfig -d /path/to/configset
```

If you are running on localhost write this command:
```bash
bin/solr zk upconfig -z localhost:9983 -n mynewconfig -d server/solr/configsets/_default/conf
```

> It's essential to understand that uploading a configuration set doesn't automatically apply the changes to collections. After uploading, you must use the Collection API's RELOAD command to reload any collections associated with the updated configuration set. This ensures that the changes take effect across the distributed Solr nodes.



## Downloading a Configuration Set from ZooKeeper

To download a configuration set from ZooKeeper to your local filesystem, you can use the `zk downconfig` command. This command ensures that you have a local copy of the configuration set that's stored in ZooKeeper. Here's what you need to know:

- **Name (-n)**: Specify the name of the configuration set in ZooKeeper that you want to download. You can find available configuration sets listed in the Admin UI under Cloud -> Tree -> configs.
- **Destination (-d)**: Provide the path where you want to save the downloaded configuration set locally. If you only provide a name, it'll be saved under $SOLR_HOME/server/solr/configsets. You can also specify an absolute path. Note that any existing configurations at the destination will be overwritten.
- **ZooKeeper Connection (-z)**: This is the connection string for ZooKeeper. If it's not defined in Solr's configuration files, you'll need to provide it explicitly.

Here's an example command that includes all parameters:

```bash
bin/solr zk downconfig -z 111.222.333.444:2181 -n mynewconfig -d /path/to/configset
```
If you are using local host use:
```bash
bin/solr zk downconfig -z localhost:9983 -n mynewconfig -d config/
```
It's a good practice to keep your configuration sets in some form of version control as the main source. This way, you'll typically use downconfig only when necessary.



